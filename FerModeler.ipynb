{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affective Computing - Final Project\n",
    "- Facial Expression Recognition with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8_KSlxWndo4j",
    "outputId": "5586633f-d469-401c-88f1-f01aef6a8421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNPgSUmydvfr"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "- The dataset is available here\n",
    "    - https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "-hJ2y6hHd6MV",
    "outputId": "293ce927-54d2-4f40-fb96-3f6d5636c03f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('drive/My Drive/Faks/Afektivno/projekt/data/fer2013.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Directory structures where images will be saved to their respective folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "2xAz67HreGAX",
    "outputId": "fb496bbd-5521-4278-ba89-bd6938e95875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/images\n",
      "/content/images/train\n",
      "/content/images\n",
      "/content/images/test\n",
      "/content/images\n",
      "/content/images/validation\n",
      "/content/images\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "%mkdir images\n",
    "%cd images\n",
    "%mkdir train test validation\n",
    "%cd train\n",
    "%mkdir Angry Disgust Fear Happy Sad Surprise Neutral\n",
    "%cd ..\n",
    "%cd test \n",
    "%mkdir Angry Disgust Fear Happy Sad Surprise Neutral\n",
    "%cd ..\n",
    "%cd validation \n",
    "%mkdir Angry Disgust Fear Happy Sad Surprise Neutral\n",
    "%cd ..\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will be great for train, test, and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "2IZVp-Fbe3Ah",
    "outputId": "28b2414a-b5ae-42a1-c53d-3d7249c9e3ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training       28709\n",
       "PrivateTest     3589\n",
       "PublicTest      3589\n",
       "Name: Usage, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Usage'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multi-class classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vbcMq7MggAf-"
   },
   "outputs": [],
   "source": [
    "classes = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classes are disballanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "gMczlO61AlE1",
    "outputId": "4e3a76cf-5722-4a9f-c8c3-67704011d70b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    8989\n",
       "6    6198\n",
       "4    6077\n",
       "2    5121\n",
       "0    4953\n",
       "5    4002\n",
       "1     547\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Data Preparation\n",
    "- Each row of PIXELS attribute consists of a string representing pixels\n",
    "    - Has 2304 elements (48x48)\n",
    "- Will get converted to list of ints and reshaped to 2D array\n",
    "- Then using OpenCV the images are saved to their folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cx1i-qR1harS"
   },
   "outputs": [],
   "source": [
    "def process_image(str_pixels):\n",
    "    pixels = str_pixels.split()\n",
    "    pixels = [int(pixel) for pixel in pixels]\n",
    "    pixels = np.array(pixels)\n",
    "    pixels = pixels.reshape(48, 48)\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "88n0U0oXfl01",
    "outputId": "b5837c03-b0ab-45aa-9f70-76cee7eab379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 images...\n",
      "Processed 2000 images...\n",
      "Processed 3000 images...\n",
      "Processed 4000 images...\n",
      "Processed 5000 images...\n",
      "Processed 6000 images...\n",
      "Processed 7000 images...\n",
      "Processed 8000 images...\n",
      "Processed 9000 images...\n",
      "Processed 10000 images...\n",
      "Processed 11000 images...\n",
      "Processed 12000 images...\n",
      "Processed 13000 images...\n",
      "Processed 14000 images...\n",
      "Processed 15000 images...\n",
      "Processed 16000 images...\n",
      "Processed 17000 images...\n",
      "Processed 18000 images...\n",
      "Processed 19000 images...\n",
      "Processed 20000 images...\n",
      "Processed 21000 images...\n",
      "Processed 22000 images...\n",
      "Processed 23000 images...\n",
      "Processed 24000 images...\n",
      "Processed 25000 images...\n",
      "Processed 26000 images...\n",
      "Processed 27000 images...\n",
      "Processed 28000 images...\n",
      "Processed 29000 images...\n",
      "Processed 30000 images...\n",
      "Processed 31000 images...\n",
      "Processed 32000 images...\n",
      "Processed 33000 images...\n",
      "Processed 34000 images...\n",
      "Processed 35000 images...\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for row in df.itertuples(index=False):\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print(f'Processed {i} images...')\n",
    "    \n",
    "    img = process_image(row.pixels)\n",
    "    curr_emotion = classes[row.emotion]\n",
    "\n",
    "    if row.Usage == 'Training':\n",
    "        cv2.imwrite(f'/content/images/train/{curr_emotion}/{i}.jpg', img)\n",
    "    elif row.Usage == 'PublicTest':\n",
    "        cv2.imwrite(f'/content/images/test/{curr_emotion}/{i}.jpg', img)\n",
    "    else:\n",
    "        cv2.imwrite(f'/content/images/validation/{curr_emotion}/{i}.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vl2So-ohhfOV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have 7 classes of 48x48 images\n",
    "- After some testing batch size of 64 seems to be working pretty well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QBeINEcqiP08"
   },
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "img_rows, img_cols = 48, 48\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2AtbtNTHiS-O"
   },
   "outputs": [],
   "source": [
    "train_data_dir = '/content/images/train'\n",
    "validation_data_dir = '/content/images/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsdxVK9fiXe-"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Pv3XgWKFiZIF",
    "outputId": "5d88014b-dc8a-4895-caec-a4a8dd7aa421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here is the model\n",
    "- Tried over 15 architectures and this one yields the best accuracy on the test set\n",
    "- Transfer learning approach didn't get over 40% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfwW6Bv9iat8"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal', input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal', input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YUaayN3eidy8",
    "outputId": "0f4baff8-3e47-4011-a610-146a34425986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 17,483,431\n",
      "Trainable params: 17,464,615\n",
      "Non-trainable params: 18,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Will also define some callbacks\n",
    "    - Early stopping\n",
    "    - Reduce learning rate on plateau\n",
    "- Model is trained for 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wQKIjrhyifdN",
    "outputId": "7589de98-54df-421f-a72a-1eff9a364743"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-ff68f7e8298d>:44: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 2.3540 - accuracy: 0.1802\n",
      "Epoch 00001: val_loss improved from inf to 1.80696, saving model to FERModel.h5\n",
      "448/448 [==============================] - 20s 44ms/step - loss: 2.3530 - accuracy: 0.1804 - val_loss: 1.8070 - val_accuracy: 0.2419 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.8825 - accuracy: 0.2184\n",
      "Epoch 00002: val_loss improved from 1.80696 to 1.77626, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.8825 - accuracy: 0.2184 - val_loss: 1.7763 - val_accuracy: 0.2567 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.8050 - accuracy: 0.2493\n",
      "Epoch 00003: val_loss improved from 1.77626 to 1.76356, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.8049 - accuracy: 0.2495 - val_loss: 1.7636 - val_accuracy: 0.2528 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.7649 - accuracy: 0.2733\n",
      "Epoch 00004: val_loss improved from 1.76356 to 1.68188, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.7649 - accuracy: 0.2733 - val_loss: 1.6819 - val_accuracy: 0.3097 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.7004 - accuracy: 0.3075\n",
      "Epoch 00005: val_loss did not improve from 1.68188\n",
      "448/448 [==============================] - 18s 41ms/step - loss: 1.7005 - accuracy: 0.3076 - val_loss: 1.6834 - val_accuracy: 0.3527 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.6291 - accuracy: 0.3489\n",
      "Epoch 00006: val_loss improved from 1.68188 to 1.55116, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.6290 - accuracy: 0.3490 - val_loss: 1.5512 - val_accuracy: 0.4093 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.5484 - accuracy: 0.3836\n",
      "Epoch 00007: val_loss improved from 1.55116 to 1.53725, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.5483 - accuracy: 0.3835 - val_loss: 1.5373 - val_accuracy: 0.4241 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.5058 - accuracy: 0.4068\n",
      "Epoch 00008: val_loss improved from 1.53725 to 1.39026, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.5057 - accuracy: 0.4068 - val_loss: 1.3903 - val_accuracy: 0.4414 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.4737 - accuracy: 0.4210\n",
      "Epoch 00009: val_loss improved from 1.39026 to 1.34258, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.4737 - accuracy: 0.4210 - val_loss: 1.3426 - val_accuracy: 0.4866 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.4518 - accuracy: 0.4318\n",
      "Epoch 00010: val_loss improved from 1.34258 to 1.33011, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.4518 - accuracy: 0.4318 - val_loss: 1.3301 - val_accuracy: 0.4883 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.4290 - accuracy: 0.4473\n",
      "Epoch 00011: val_loss improved from 1.33011 to 1.28973, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.4292 - accuracy: 0.4474 - val_loss: 1.2897 - val_accuracy: 0.4941 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.4174 - accuracy: 0.4584\n",
      "Epoch 00012: val_loss did not improve from 1.28973\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.4174 - accuracy: 0.4584 - val_loss: 1.3406 - val_accuracy: 0.4665 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.4023 - accuracy: 0.4590\n",
      "Epoch 00013: val_loss improved from 1.28973 to 1.27422, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.4021 - accuracy: 0.4590 - val_loss: 1.2742 - val_accuracy: 0.5106 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.3779 - accuracy: 0.4766\n",
      "Epoch 00014: val_loss improved from 1.27422 to 1.21375, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.3776 - accuracy: 0.4769 - val_loss: 1.2138 - val_accuracy: 0.5310 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.3577 - accuracy: 0.4870\n",
      "Epoch 00015: val_loss improved from 1.21375 to 1.17485, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 43ms/step - loss: 1.3577 - accuracy: 0.4870 - val_loss: 1.1749 - val_accuracy: 0.5438 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.3322 - accuracy: 0.4979\n",
      "Epoch 00016: val_loss did not improve from 1.17485\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.3328 - accuracy: 0.4976 - val_loss: 1.1860 - val_accuracy: 0.5396 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.3209 - accuracy: 0.5048\n",
      "Epoch 00017: val_loss improved from 1.17485 to 1.14632, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.3207 - accuracy: 0.5049 - val_loss: 1.1463 - val_accuracy: 0.5586 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.3068 - accuracy: 0.5096\n",
      "Epoch 00018: val_loss did not improve from 1.14632\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.3064 - accuracy: 0.5098 - val_loss: 1.1597 - val_accuracy: 0.5566 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.2960 - accuracy: 0.5177\n",
      "Epoch 00019: val_loss improved from 1.14632 to 1.10931, saving model to FERModel.h5\n",
      "448/448 [==============================] - 20s 44ms/step - loss: 1.2960 - accuracy: 0.5177 - val_loss: 1.1093 - val_accuracy: 0.5798 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.2801 - accuracy: 0.5184\n",
      "Epoch 00020: val_loss did not improve from 1.10931\n",
      "448/448 [==============================] - 19s 41ms/step - loss: 1.2801 - accuracy: 0.5184 - val_loss: 1.1190 - val_accuracy: 0.5670 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.2702 - accuracy: 0.5269\n",
      "Epoch 00021: val_loss improved from 1.10931 to 1.08096, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.2702 - accuracy: 0.5269 - val_loss: 1.0810 - val_accuracy: 0.5876 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.2645 - accuracy: 0.5297\n",
      "Epoch 00022: val_loss did not improve from 1.08096\n",
      "448/448 [==============================] - 18s 41ms/step - loss: 1.2645 - accuracy: 0.5297 - val_loss: 1.0886 - val_accuracy: 0.5845 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.2494 - accuracy: 0.5372\n",
      "Epoch 00023: val_loss improved from 1.08096 to 1.07338, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.2496 - accuracy: 0.5371 - val_loss: 1.0734 - val_accuracy: 0.5968 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.2425 - accuracy: 0.5401\n",
      "Epoch 00024: val_loss did not improve from 1.07338\n",
      "448/448 [==============================] - 19s 41ms/step - loss: 1.2425 - accuracy: 0.5401 - val_loss: 1.0999 - val_accuracy: 0.5837 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.2386 - accuracy: 0.5444\n",
      "Epoch 00025: val_loss improved from 1.07338 to 1.04132, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 43ms/step - loss: 1.2391 - accuracy: 0.5442 - val_loss: 1.0413 - val_accuracy: 0.6049 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.2287 - accuracy: 0.5494\n",
      "Epoch 00026: val_loss did not improve from 1.04132\n",
      "448/448 [==============================] - 19s 41ms/step - loss: 1.2286 - accuracy: 0.5493 - val_loss: 1.0487 - val_accuracy: 0.6007 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.2230 - accuracy: 0.5499\n",
      "Epoch 00027: val_loss did not improve from 1.04132\n",
      "448/448 [==============================] - 18s 41ms/step - loss: 1.2224 - accuracy: 0.5503 - val_loss: 1.0479 - val_accuracy: 0.6032 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.2155 - accuracy: 0.5513\n",
      "Epoch 00028: val_loss did not improve from 1.04132\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "448/448 [==============================] - 18s 41ms/step - loss: 1.2158 - accuracy: 0.5512 - val_loss: 1.0584 - val_accuracy: 0.6063 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1818 - accuracy: 0.5640\n",
      "Epoch 00029: val_loss improved from 1.04132 to 1.01155, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.1812 - accuracy: 0.5643 - val_loss: 1.0116 - val_accuracy: 0.6275 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1790 - accuracy: 0.5672\n",
      "Epoch 00030: val_loss improved from 1.01155 to 1.00009, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.1791 - accuracy: 0.5671 - val_loss: 1.0001 - val_accuracy: 0.6267 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.1567 - accuracy: 0.5776\n",
      "Epoch 00031: val_loss improved from 1.00009 to 0.99833, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.1567 - accuracy: 0.5776 - val_loss: 0.9983 - val_accuracy: 0.6267 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1519 - accuracy: 0.5745\n",
      "Epoch 00032: val_loss did not improve from 0.99833\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.1519 - accuracy: 0.5746 - val_loss: 1.0059 - val_accuracy: 0.6239 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1589 - accuracy: 0.5727\n",
      "Epoch 00033: val_loss improved from 0.99833 to 0.98855, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.1591 - accuracy: 0.5725 - val_loss: 0.9885 - val_accuracy: 0.6336 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1527 - accuracy: 0.5776\n",
      "Epoch 00034: val_loss improved from 0.98855 to 0.98411, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 43ms/step - loss: 1.1531 - accuracy: 0.5775 - val_loss: 0.9841 - val_accuracy: 0.6325 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.1404 - accuracy: 0.5827\n",
      "Epoch 00035: val_loss did not improve from 0.98411\n",
      "448/448 [==============================] - 18s 41ms/step - loss: 1.1404 - accuracy: 0.5827 - val_loss: 0.9869 - val_accuracy: 0.6331 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1437 - accuracy: 0.5795\n",
      "Epoch 00036: val_loss did not improve from 0.98411\n",
      "448/448 [==============================] - 18s 41ms/step - loss: 1.1439 - accuracy: 0.5793 - val_loss: 0.9885 - val_accuracy: 0.6325 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1389 - accuracy: 0.5831\n",
      "Epoch 00037: val_loss did not improve from 0.98411\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "448/448 [==============================] - 18s 41ms/step - loss: 1.1391 - accuracy: 0.5832 - val_loss: 0.9917 - val_accuracy: 0.6289 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1353 - accuracy: 0.5863\n",
      "Epoch 00038: val_loss improved from 0.98411 to 0.97942, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.1353 - accuracy: 0.5860 - val_loss: 0.9794 - val_accuracy: 0.6348 - lr: 4.0000e-05\n",
      "Epoch 39/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1348 - accuracy: 0.5855\n",
      "Epoch 00039: val_loss did not improve from 0.97942\n",
      "448/448 [==============================] - 18s 41ms/step - loss: 1.1348 - accuracy: 0.5856 - val_loss: 0.9796 - val_accuracy: 0.6328 - lr: 4.0000e-05\n",
      "Epoch 40/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1365 - accuracy: 0.5833\n",
      "Epoch 00040: val_loss improved from 0.97942 to 0.97620, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.1366 - accuracy: 0.5832 - val_loss: 0.9762 - val_accuracy: 0.6336 - lr: 4.0000e-05\n",
      "Epoch 41/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1268 - accuracy: 0.5882\n",
      "Epoch 00041: val_loss improved from 0.97620 to 0.97607, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.1263 - accuracy: 0.5884 - val_loss: 0.9761 - val_accuracy: 0.6328 - lr: 4.0000e-05\n",
      "Epoch 42/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1263 - accuracy: 0.5884\n",
      "Epoch 00042: val_loss improved from 0.97607 to 0.97607, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.1260 - accuracy: 0.5887 - val_loss: 0.9761 - val_accuracy: 0.6353 - lr: 4.0000e-05\n",
      "Epoch 43/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1333 - accuracy: 0.5882\n",
      "Epoch 00043: val_loss did not improve from 0.97607\n",
      "448/448 [==============================] - 18s 41ms/step - loss: 1.1330 - accuracy: 0.5882 - val_loss: 0.9781 - val_accuracy: 0.6334 - lr: 4.0000e-05\n",
      "Epoch 44/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1296 - accuracy: 0.5889\n",
      "Epoch 00044: val_loss improved from 0.97607 to 0.97374, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.1293 - accuracy: 0.5891 - val_loss: 0.9737 - val_accuracy: 0.6364 - lr: 4.0000e-05\n",
      "Epoch 45/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1290 - accuracy: 0.5850\n",
      "Epoch 00045: val_loss did not improve from 0.97374\n",
      "448/448 [==============================] - 18s 41ms/step - loss: 1.1289 - accuracy: 0.5851 - val_loss: 0.9753 - val_accuracy: 0.6381 - lr: 4.0000e-05\n",
      "Epoch 46/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1281 - accuracy: 0.5875\n",
      "Epoch 00046: val_loss improved from 0.97374 to 0.97196, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.1284 - accuracy: 0.5875 - val_loss: 0.9720 - val_accuracy: 0.6376 - lr: 4.0000e-05\n",
      "Epoch 47/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1226 - accuracy: 0.5880\n",
      "Epoch 00047: val_loss improved from 0.97196 to 0.97164, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.1223 - accuracy: 0.5881 - val_loss: 0.9716 - val_accuracy: 0.6395 - lr: 4.0000e-05\n",
      "Epoch 48/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1233 - accuracy: 0.5920\n",
      "Epoch 00048: val_loss improved from 0.97164 to 0.97113, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 43ms/step - loss: 1.1234 - accuracy: 0.5919 - val_loss: 0.9711 - val_accuracy: 0.6384 - lr: 4.0000e-05\n",
      "Epoch 49/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1265 - accuracy: 0.5898\n",
      "Epoch 00049: val_loss improved from 0.97113 to 0.96734, saving model to FERModel.h5\n",
      "448/448 [==============================] - 19s 42ms/step - loss: 1.1265 - accuracy: 0.5898 - val_loss: 0.9673 - val_accuracy: 0.6378 - lr: 4.0000e-05\n",
      "Epoch 50/50\n",
      "447/448 [============================>.] - ETA: 0s - loss: 1.1237 - accuracy: 0.5885\n",
      "Epoch 00050: val_loss did not improve from 0.96734\n",
      "448/448 [==============================] - 18s 41ms/step - loss: 1.1237 - accuracy: 0.5884 - val_loss: 0.9714 - val_accuracy: 0.6376 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'FERModel.h5',\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=9,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_delta=0.0001\n",
    ")\n",
    "\n",
    "callbacks = [earlystop, checkpoint, reduce_lr]\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(lr=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "nb_train_samples = 28709\n",
    "nb_validation_samples = 3589\n",
    "epochs = 50\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Performance Testing\n",
    "\n",
    "- The model will now be evaluated on previously unseen data (only train and valid sets were visible in the training process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "1yGymDm88E9F",
    "outputId": "919cfecc-027f-4e23-e417-12dee9e8d3eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_dir = '/content/images/test/'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5cLzxvnM8azw",
    "outputId": "d0b79e84-7c28-4dd0-da3f-e6f633a26ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-ea3db7081abc>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoueoOV78xTp"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Obtained 63% accuracy on the train set\n",
    "- Dummy model (predicts random classes) would get around 14%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6DF6_VJk8zby",
    "outputId": "90756c93-9c2d-4da8-c933-58bb5e43a203"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.630259096622467"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "FerModeler.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
